{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":49,"outputs":[{"output_type":"stream","text":"['test', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\nfrom torchvision.datasets import MNIST\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nrandom.seed(7)\nimport time\nimport pickle\nfrom catboost import CatBoostRegressor, Pool\n#data scaling\nfrom sklearn.preprocessing import StandardScaler\n#hyperparameter optimization\nfrom sklearn.model_selection import GridSearchCV\n#support vector machine model\nfrom sklearn.svm import NuSVR, SVR\n#kernel ridge model\nfrom sklearn.kernel_ridge import KernelRidge\n#data visualization\nimport matplotlib.pyplot as plt","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttf = df['time_to_failure'].values\nindex_start = np.nonzero(np.diff(ttf) > 0)[0] + 1\nindex_start = np.insert(index_start, 0, 0)\ndict_df={}\nfor i in range(len(index_start)):\n    if i<(len(index_start)-1):\n        df_tmp=df[index_start[i]:index_start[i+1]]\n    else:\n        df_tmp=df[index_start[i]:]       \n    dict_df[\"df\"+str(i)]=df_tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomChoice(l):\n    return random.randint(0, l - 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomTrainingExample(df_dict):\n    k = len(df_dict)\n    num=randomChoice(k)\n    #print(num)\n    len_df=len(df_dict['df'+str(num)])\n    idx_start=random.randint(0,len_df-149999)\n    idx_end=idx_start+150000\n    #print('Start Index:',idx_start)\n    #print('End Index:',idx_end)\n    df_tmp=df_dict['df'+str(num)]\n    sample_x=df_tmp.iloc[idx_start:idx_end]['acoustic_data']\n    sample_y=df_tmp.iloc[idx_start:idx_end]['time_to_failure']  \n    sample_x=np.array(sample_x)\n    sample_y=np.array(sample_y)    \n    uid =str(num)+'-'+str(idx_start)+'-'+str(idx_end)\n    return uid,sample_x,sample_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uid,xtrain,ytrain=randomTrainingExample(dict_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_final_x={}\ndict_final_y={}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_examples=5000\nnow=time.time()\nwhile(n_examples):\n    while(uid in dict_final_x.keys()):\n        uid,xtrain,ytrain=randomTrainingExample(dict_df)\n    xtrain=np.array(xtrain)\n    ytrain=np.array(ytrain)\n    xtrain= xtrain.astype(np.float32)\n    ytrain= ytrain.astype(np.float32)\n    dict_final_x[uid]=xtrain\n    dict_final_y[uid]=ytrain\n    n_examples-=1\nthen=time.time()\nprint(\"Time Taken:\",then-now)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_epochs = 200\nbatch_size = 10\nlearning_rate = 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloader = DataLoader(list(dict_final_x.keys()), batch_size=batch_size, shuffle=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_x(uid_list):\n        x=dict_final_x[uid_list]\n        return x\n        \ndef get_y(uid_list):\n        y=dict_final_y[uid_list]\n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import skew\nfrom scipy.stats import  kurtosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_features(X):\n    strain = []\n    strain.append(X.mean())\n    strain.append(X.std())\n    strain.append(X.min())\n    strain.append(X.max())\n    strain.append(kurtosis(X))\n    strain.append(skew(X))\n    strain.append(np.quantile(X,0.01))\n    strain.append(np.quantile(X,0.05))\n    strain.append(np.quantile(X,0.95))\n    strain.append(np.quantile(X,0.99))\n    strain.append(np.abs(X).max())\n    strain.append(np.abs(X).mean())\n    strain.append(np.abs(X).std())\n    return pd.Series(strain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs=170\nprint(dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.DataFrame()\nY_train=pd.Series()\nfor data in dataloader:\n#         print(data)\n        for i in data:\n            x_train = get_x(i)\n#             print(x_train)\n#             print(i)\n#         print('Xtrain:')\n#         print(x_train.shape)\n            y_train=get_y(i)\n            ch = gen_features(x_train)\n            X_train = X_train.append(ch, ignore_index=True)\n            Y_train = Y_train.append(pd.Series(y_train[-1]))\n#         print(\"sdsd\")\nprint(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pool = Pool(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = CatBoostRegressor(iterations=10000, loss_function='MAE', boosting_type='Ordered')\nm.fit(X_train_scaled, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.best_score_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for seg_id in submission.index:\n    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n    ch = gen_features(seg['acoustic_data'])\n    X_test = X_test.append(ch, ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(X_test)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = m.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['time_to_failure'] =Y_test\nsubmission.to_csv('submission1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}