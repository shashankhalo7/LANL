{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[{"output_type":"stream","text":"['test', 'sample_submission.csv', 'train.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torchvision.datasets import MNIST\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nrandom.seed(7)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv', dtype = {'acoustic_data': np.int16, 'time_to_failure': np.float32} ) # float32 is enough :)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttf = df['time_to_failure'].values\nindex_start = np.nonzero(np.diff(ttf) > 0)[0] + 1\nindex_start = np.insert(index_start, 0, 0)\ndict_df={}\nfor i in range(len(index_start)-1):\n  df_tmp=df[index_start[i]:index_start[i+1]]\n  dict_df[\"df\"+str(i)]=df_tmp","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomChoice(l):\n    return random.randint(0, l - 1)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"150000"},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomTrainingExample(df_dict):\n  k = len(df_dict)\n  num=randomChoice(k)\n  print(num)\n  len_df=len(df_dict['df'+str(num)])\n  idx_start=random.randint(0,len_df-149999)\n  idx_end=idx_start+150000\n  print('Start Index:',idx_start)\n  print('End Index:',idx_end)\n  df_tmp=df_dict['df'+str(num)]\n  sample_x=df_tmp.iloc[idx_start:idx_end]['acoustic_data']\n  sample_y=df_tmp.iloc[idx_start:idx_end]['time_to_failure']\n\n  sample_x1=np.diff(sample_x)\n  sample_y1=np.diff(sample_y)\n  meanx1=np.mean(sample_x1)\n  meany1=np.mean(sample_y1)\n  sample_x1=np.append(sample_x1,meanx1)\n  sample_y1=np.append( sample_y1,meany1)\n\n  sample_x2=np.diff(sample_x1)\n  sample_y2=np.diff(sample_y1)\n  meanx2=np.mean(sample_x2)\n  meany2=np.mean(sample_y2)\n  sample_x2=np.append(sample_x2,meanx2)\n  sample_y2=np.append(sample_y2,meany2)\n#   sample_y2=np.append(sample_y2,meany2)\n\n  sample_x=np.array(sample_x)\n  sample_y=np.array(sample_y)\n  sample_x1=np.array(sample_x1)\n  sample_y1=np.array(sample_y1)\n  sample_x2=np.array(sample_x2)\n  sample_y2=np.array(sample_y2)\n\n  print(sample_x.shape)\n  print(sample_x1.shape)\n  print(sample_x2.shape)\n  xtable= [[ 0 for i in range(100) ] for j in range(1500)]\n  ytable= [[ 0 for i in range(100) ] for j in range(1500)]\n  for i in range(100):\n    for j in range(1500):\n        x=[]\n        x1=[]\n        x2=[]\n        x.append(sample_x[1500*i+j])\n        x1.append(sample_x1[1500*i+j])\n        x2.append(sample_x2[1500*i+j])\n        xtable[j][i]=x+x1+x2\n  for i in range(100):\n    for j in range(1500):\n        x=[]\n        x1=[]\n        x2=[]\n        x.append(sample_y[1500*i+j])\n        x1.append(sample_y1[1500*i+j])\n        x2.append(sample_y2[1500*i+j])\n        ytable[j][i]=x+x1+x2\n  return xtable,ytable \n  \n    ","execution_count":240,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,ytrain=randomTrainingExample(dict_df)\n","execution_count":241,"outputs":[{"output_type":"stream","text":"0\nStart Index: 1222022\nEnd Index: 1372022\n(150000,)\n(150000,)\n(150000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain[1499][99]","execution_count":242,"outputs":[{"output_type":"execute_result","execution_count":242,"data":{"text/plain":"[1.1137956, -2.5535357e-07, -1.7023685e-12]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain=np.array(xtrain)\nytrain=np.array(ytrain)","execution_count":243,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain","execution_count":244,"outputs":[{"output_type":"execute_result","execution_count":244,"data":{"text/plain":"array([[[ 3.00000000e+00,  1.00000000e+00, -3.00000000e+00],\n        [ 1.10000000e+01, -3.00000000e+00, -3.00000000e+00],\n        [ 6.00000000e+00,  2.00000000e+00, -2.00000000e+00],\n        ...,\n        [ 8.00000000e+00,  1.00000000e+00, -4.00000000e+00],\n        [-1.00000000e+00,  2.00000000e+00,  6.00000000e+00],\n        [ 1.00000000e+00,  4.00000000e+00, -2.00000000e+00]],\n\n       [[ 4.00000000e+00, -2.00000000e+00,  2.00000000e+00],\n        [ 8.00000000e+00, -6.00000000e+00,  2.00000000e+00],\n        [ 8.00000000e+00,  0.00000000e+00, -4.00000000e+00],\n        ...,\n        [ 9.00000000e+00, -3.00000000e+00,  3.00000000e+00],\n        [ 1.00000000e+00,  8.00000000e+00, -8.00000000e+00],\n        [ 5.00000000e+00,  2.00000000e+00, -2.00000000e+00]],\n\n       [[ 2.00000000e+00,  0.00000000e+00,  3.00000000e+00],\n        [ 2.00000000e+00, -4.00000000e+00,  8.00000000e+00],\n        [ 8.00000000e+00, -4.00000000e+00,  6.00000000e+00],\n        ...,\n        [ 6.00000000e+00,  0.00000000e+00, -6.00000000e+00],\n        [ 9.00000000e+00,  0.00000000e+00, -1.00000000e+00],\n        [ 7.00000000e+00,  0.00000000e+00, -2.00000000e+00]],\n\n       ...,\n\n       [[ 7.00000000e+00,  0.00000000e+00,  6.00000000e+00],\n        [ 8.00000000e+00,  2.00000000e+00, -7.00000000e+00],\n        [ 4.00000000e+00, -1.00000000e+00, -4.00000000e+00],\n        ...,\n        [ 3.00000000e+00,  1.00000000e+00, -2.00000000e+00],\n        [ 3.00000000e+00,  0.00000000e+00, -2.00000000e+00],\n        [ 5.00000000e+00, -1.00000000e+00,  2.00000000e+00]],\n\n       [[ 7.00000000e+00,  6.00000000e+00, -8.00000000e+00],\n        [ 1.00000000e+01, -5.00000000e+00,  6.00000000e+00],\n        [ 3.00000000e+00, -5.00000000e+00,  6.00000000e+00],\n        ...,\n        [ 4.00000000e+00, -1.00000000e+00, -3.00000000e+00],\n        [ 3.00000000e+00, -2.00000000e+00,  2.00000000e+00],\n        [ 4.00000000e+00,  1.00000000e+00, -9.99986667e-01]],\n\n       [[ 1.30000000e+01, -2.00000000e+00, -1.00000000e+00],\n        [ 5.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n        [-2.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n        ...,\n        [ 3.00000000e+00, -4.00000000e+00,  6.00000000e+00],\n        [ 1.00000000e+00,  0.00000000e+00,  4.00000000e+00],\n        [ 5.00000000e+00,  1.33334222e-05, -6.66662222e-06]]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 100\nbatch_size = 128\nlearning_rate = 1e-3","execution_count":245,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n","execution_count":246,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrainimg=img_transform(xtrain)\n# ytrainimg=img_transform(ytrain)\n# dataloader = DataLoader(xtrainimg, batch_size=batch_size, shuffle=True)","execution_count":247,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"expected type torch.DoubleTensor but got torch.FloatTensor","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-247-646ff82d696f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtrainimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# ytrainimg=img_transform(ytrain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dataloader = DataLoader(xtrainimg, batch_size=batch_size, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected type torch.DoubleTensor but got torch.FloatTensor"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n            nn.ReLU(True),\n            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = autoencoder().cuda()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\nweight_decay=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        img = xtrainimg\n        img = Variable(img).cuda()\n        # ===================forward=====================\n        output = model(img)\n        loss = criterion(output, img)\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================log========================\n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch+1, num_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_img(output.cpu().data)\nsave_image(pic, './dc_img/image_{}.png'.format(epoch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}