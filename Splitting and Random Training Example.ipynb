{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[{"output_type":"stream","text":"['test', 'sample_submission.csv', 'train.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torchvision.datasets import MNIST\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nrandom.seed(7)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv', dtype = {'acoustic_data': np.int16, 'time_to_failure': np.float32} ) # float32 is enough :)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttf = df['time_to_failure'].values\nindex_start = np.nonzero(np.diff(ttf) > 0)[0] + 1\nindex_start = np.insert(index_start, 0, 0)\ndict_df={}\nfor i in range(len(index_start)-1):\n  df_tmp=df[index_start[i]:index_start[i+1]]\n  dict_df[\"df\"+str(i)]=df_tmp","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomChoice(l):\n    return random.randint(0, l - 1)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"150000"},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomTrainingExample(df_dict):\n  k = len(df_dict)\n  num=randomChoice(k)\n  print(num)\n  len_df=len(df_dict['df'+str(num)])\n  idx_start=random.randint(0,len_df-149999)\n  idx_end=idx_start+150000\n  print('Start Index:',idx_start)\n  print('End Index:',idx_end)\n  df_tmp=df_dict['df'+str(num)]\n  sample_x=df_tmp.iloc[idx_start:idx_end]['acoustic_data']\n  sample_y=df_tmp.iloc[idx_start:idx_end]['time_to_failure']\n\n  sample_x1=np.diff(sample_x)\n  sample_y1=np.diff(sample_y)\n  meanx1=np.mean(sample_x1)\n  meany1=np.mean(sample_y1)\n  sample_x1=np.append(sample_x1,meanx1)\n  sample_y1=np.append( sample_y1,meany1)\n\n  sample_x2=np.diff(sample_x1)\n  sample_y2=np.diff(sample_y1)\n  meanx2=np.mean(sample_x2)\n  meany2=np.mean(sample_y2)\n  sample_x2=np.append(sample_x2,meanx2)\n  sample_y2=np.append(sample_y2,meany2)\n#   sample_y2=np.append(sample_y2,meany2)\n\n  sample_x=np.array(sample_x)\n  sample_y=np.array(sample_y)\n  sample_x1=np.array(sample_x1)\n  sample_y1=np.array(sample_y1)\n  sample_x2=np.array(sample_x2)\n  sample_y2=np.array(sample_y2)\n\n  print(sample_x.shape)\n  print(sample_x1.shape)\n  print(sample_x2.shape)\n  xtable= [[ 0 for i in range(100) ] for j in range(1500)]\n  ytable= [[ 0 for i in range(100) ] for j in range(1500)]\n  for i in range(100):\n    for j in range(1500):\n        x=[]\n        x1=[]\n        x2=[]\n        x.append(sample_x[1500*i+j])\n        x1.append(sample_x1[1500*i+j])\n        x2.append(sample_x2[1500*i+j])\n        xtable[j][i]=x+x1+x2\n  for i in range(100):\n    for j in range(1500):\n        x=[]\n        x1=[]\n        x2=[]\n        x.append(sample_y[1500*i+j])\n        x1.append(sample_y1[1500*i+j])\n        x2.append(sample_y2[1500*i+j])\n        ytable[j][i]=x+x1+x2\n  return xtable,ytable \n  \n    ","execution_count":275,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,ytrain=randomTrainingExample(dict_df)\n","execution_count":276,"outputs":[{"output_type":"stream","text":"13\nStart Index: 17937896\nEnd Index: 18087896\n(150000,)\n(150000,)\n(150000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain[1499][99]","execution_count":277,"outputs":[{"output_type":"execute_result","execution_count":277,"data":{"text/plain":"[3.8684955, -2.5535437e-07, -1.7023738e-12]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain=np.array(xtrain)\nytrain=np.array(ytrain)","execution_count":278,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain= xtrain.astype(np.float32)\nytrain= ytrain.astype(np.float32)","execution_count":283,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain","execution_count":284,"outputs":[{"output_type":"execute_result","execution_count":284,"data":{"text/plain":"array([[[ 0.0000000e+00,  4.0000000e+00,  0.0000000e+00],\n        [ 8.0000000e+00, -3.0000000e+00,  4.0000000e+00],\n        [ 3.0000000e+00,  2.0000000e+00, -2.0000000e+00],\n        ...,\n        [ 5.0000000e+00, -5.0000000e+00,  1.1000000e+01],\n        [-2.0000000e+00,  6.0000000e+00, -3.0000000e+00],\n        [ 1.0000000e+00,  3.0000000e+00, -4.0000000e+00]],\n\n       [[ 4.0000000e+00,  4.0000000e+00, -6.0000000e+00],\n        [ 5.0000000e+00,  1.0000000e+00, -3.0000000e+00],\n        [ 5.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n        ...,\n        [ 0.0000000e+00,  6.0000000e+00, -3.0000000e+00],\n        [ 4.0000000e+00,  3.0000000e+00, -8.0000000e+00],\n        [ 4.0000000e+00, -1.0000000e+00,  1.0000000e+00]],\n\n       [[ 8.0000000e+00, -2.0000000e+00,  4.0000000e+00],\n        [ 6.0000000e+00, -2.0000000e+00,  6.0000000e+00],\n        [ 5.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n        ...,\n        [ 6.0000000e+00,  3.0000000e+00, -6.0000000e+00],\n        [ 7.0000000e+00, -5.0000000e+00,  3.0000000e+00],\n        [ 3.0000000e+00,  0.0000000e+00,  4.0000000e+00]],\n\n       ...,\n\n       [[ 7.0000000e+00, -5.0000000e+00,  8.0000000e+00],\n        [ 7.0000000e+00, -4.0000000e+00,  5.0000000e+00],\n        [ 6.0000000e+00,  3.0000000e+00, -7.0000000e+00],\n        ...,\n        [ 5.0000000e+00,  1.0000000e+00, -1.0000000e+00],\n        [ 6.0000000e+00,  2.0000000e+00, -9.0000000e+00],\n        [ 7.0000000e+00, -3.0000000e+00,  1.0000000e+00]],\n\n       [[ 2.0000000e+00,  3.0000000e+00,  0.0000000e+00],\n        [ 3.0000000e+00,  1.0000000e+00, -2.0000000e+00],\n        [ 9.0000000e+00, -4.0000000e+00,  0.0000000e+00],\n        ...,\n        [ 6.0000000e+00,  0.0000000e+00, -8.0000000e+00],\n        [ 8.0000000e+00, -7.0000000e+00,  7.0000000e+00],\n        [ 4.0000000e+00, -2.0000000e+00,  2.0000134e+00]],\n\n       [[ 5.0000000e+00,  3.0000000e+00, -6.0000000e+00],\n        [ 4.0000000e+00, -1.0000000e+00,  3.0000000e+00],\n        [ 5.0000000e+00, -4.0000000e+00,  5.0000000e+00],\n        ...,\n        [ 6.0000000e+00, -8.0000000e+00,  1.4000000e+01],\n        [ 1.0000000e+00,  0.0000000e+00,  3.0000000e+00],\n        [ 2.0000000e+00,  1.3333422e-05, -2.6666756e-05]]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 100\nbatch_size = 128\nlearning_rate = 1e-3","execution_count":285,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n","execution_count":286,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrainimg=img_transform(xtrain)\nytrainimg=img_transform(ytrain)\ndataloader = DataLoader(xtrainimg, batch_size=batch_size, shuffle=True)","execution_count":294,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n            nn.ReLU(True),\n            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n            nn.ReLU(True),\n            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n            nn.ReLU(True),\n            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","execution_count":289,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = autoencoder().cuda()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\nweight_decay=1e-5)","execution_count":290,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        img, _ = data\n        img = Variable(img).cuda()\n        # ===================forward=====================\n        output = model(img)\n        loss = criterion(output, img)\n        # ===================backward====================\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # ===================log========================\n    print('epoch [{}/{}], loss:{:.4f}'\n          .format(epoch+1, num_epochs, loss.data[0]))\n    if epoch % 10 == 0:\n        pic = to_img(output.cpu().data)\nsave_image(pic, './dc_img/image_{}.png'.format(epoch))","execution_count":296,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [3, 1500, 100] instead","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-296-13c4aaa1a1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# ===================forward=====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# ===================backward====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-289-3e3cf46cf85f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [3, 1500, 100] instead"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}