{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(7)\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.95693302154541\n"
     ]
    }
   ],
   "source": [
    "then = time.time()\n",
    "df = pd.read_csv('data/train/train.csv',dtype = {'acoustic_data': np.int16, 'time_to_failure': np.float64} ) # float32 is enough :)\n",
    "now = time.time()\n",
    "print(now-then)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttf = df['time_to_failure'].values\n",
    "index_start = np.nonzero(np.diff(ttf) > 0)[0] + 1\n",
    "index_start = np.insert(index_start, 0, 0)\n",
    "dict_df={}\n",
    "for i in range(len(index_start)):\n",
    "    if i<(len(index_start)-1):\n",
    "        df_tmp=df[index_start[i]:index_start[i+1]]\n",
    "    else:\n",
    "        df_tmp=df[index_start[i]:]       \n",
    "    dict_df[\"df\"+str(i)]=df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "    return random.randint(0, l - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrainingExample(df_dict):\n",
    "    k = len(df_dict)\n",
    "    num=randomChoice(k)\n",
    "    #print(num)\n",
    "    len_df=len(df_dict['df'+str(num)])\n",
    "    idx_start=random.randint(0,len_df-149999)\n",
    "    idx_end=idx_start+150000\n",
    "    #print('Start Index:',idx_start)\n",
    "    #print('End Index:',idx_end)\n",
    "    df_tmp=df_dict['df'+str(num)]\n",
    "    sample_x=df_tmp.iloc[idx_start:idx_end]['acoustic_data']\n",
    "    sample_y=df_tmp.iloc[idx_start:idx_end]['time_to_failure']\n",
    "\n",
    "    '''sample_x1=np.diff(sample_x)\n",
    "    sample_y1=np.diff(sample_y)\n",
    "    meanx1=np.mean(sample_x1)\n",
    "    meany1=np.mean(sample_y1)\n",
    "    sample_x1=np.append(sample_x1,meanx1)\n",
    "    sample_y1=np.append( sample_y1,meany1)\n",
    "\n",
    "    sample_x2=np.diff(sample_x1)\n",
    "    sample_y2=np.diff(sample_y1)\n",
    "    meanx2=np.mean(sample_x2)\n",
    "    meany2=np.mean(sample_y2)\n",
    "    sample_x2=np.append(sample_x2,meanx2)\n",
    "    sample_y2=np.append(sample_y2,meany2)\n",
    "  #   sample_y2=np.append(sample_y2,meany2)'''\n",
    "  \n",
    "    sample_x=np.array(sample_x)\n",
    "    sample_y=np.array(sample_y)\n",
    "    ''' sample_x1=np.array(sample_x1)\n",
    "    sample_y1=np.array(sample_y1)\n",
    "    sample_x2=np.array(sample_x2)\n",
    "    sample_y2=np.array(sample_y2)\n",
    "\n",
    "    #print(sample_x.shape)\n",
    "    #print(sample_x1.shape)\n",
    "    #print(sample_x2.shape)'''\n",
    "    xtable= [[ 0 for i in range(300) ] for j in range(500)]\n",
    "    ytable= [[ 0 for i in range(300) ] for j in range(500)]\n",
    "    for i in range(300):\n",
    "        for j in range(500):\n",
    "            x=[]\n",
    "            #x1=[]\n",
    "            #x2=[]\n",
    "            x.append(sample_x[500*i+j])\n",
    "            #x1.append(sample_x1[500*i+j])\n",
    "            #x2.append(sample_x2[500*i+j])\n",
    "            xtable[j][i]=x#+x1+x2\n",
    "    for i in range(300):\n",
    "        for j in range(500):\n",
    "            x=[]\n",
    "            #x1=[]\n",
    "            #x2=[]\n",
    "            x.append(sample_y[500*i+j])\n",
    "            #x1.append(sample_y1[500*i+j])\n",
    "            #x2.append(sample_y2[500*i+j])\n",
    "            ytable[j][i]=x\n",
    "    uid =str(num)+'-'+str(idx_start)+'-'+str(idx_end)\n",
    "    return uid,xtable,ytable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid,xtrain,ytrain=randomTrainingExample(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5-11753277-11903277'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = np.array(xtrain)\n",
    "#a[0][0]\n",
    "uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=np.array(xtrain)\n",
    "ytrain=np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain= xtrain.astype(np.float32)\n",
    "ytrain= ytrain.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.],\n",
       "        [ 0.],\n",
       "        [ 5.],\n",
       "        ...,\n",
       "        [ 4.],\n",
       "        [ 8.],\n",
       "        [ 7.]],\n",
       "\n",
       "       [[ 1.],\n",
       "        [ 2.],\n",
       "        [ 4.],\n",
       "        ...,\n",
       "        [ 8.],\n",
       "        [ 7.],\n",
       "        [ 3.]],\n",
       "\n",
       "       [[ 3.],\n",
       "        [ 3.],\n",
       "        [ 8.],\n",
       "        ...,\n",
       "        [ 5.],\n",
       "        [ 2.],\n",
       "        [ 6.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 6.],\n",
       "        [ 2.],\n",
       "        [-1.],\n",
       "        ...,\n",
       "        [ 6.],\n",
       "        [ 6.],\n",
       "        [ 2.]],\n",
       "\n",
       "       [[ 7.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        ...,\n",
       "        [ 7.],\n",
       "        [11.],\n",
       "        [ 5.]],\n",
       "\n",
       "       [[ 4.],\n",
       "        [ 0.],\n",
       "        [ 2.],\n",
       "        ...,\n",
       "        [ 6.],\n",
       "        [ 6.],\n",
       "        [ 3.]]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainimg=img_transform(xtrain)\n",
    "ytrainimg=img_transform(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_final_x={}\n",
    "dict_final_y={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 95.64224028587341\n"
     ]
    }
   ],
   "source": [
    "n_examples=17*10\n",
    "now=time.time()\n",
    "while(n_examples):\n",
    "    while(uid in dict_final_x.keys()):\n",
    "        uid,xtrain,ytrain=randomTrainingExample(dict_df)\n",
    "    xtrain=np.array(xtrain)\n",
    "    ytrain=np.array(ytrain)\n",
    "    xtrain= xtrain.astype(np.float32)\n",
    "    ytrain= ytrain.astype(np.float32)\n",
    "    xtrainimg=img_transform(xtrain)\n",
    "    ytrainimg=img_transform(ytrain)\n",
    "    dict_final_x[uid]=xtrainimg\n",
    "    dict_final_y[uid]=ytrainimg\n",
    "    n_examples-=1\n",
    "then=time.time()\n",
    "print(\"Time Taken:\",then-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 300])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_final_x[uid].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=(2,0)),  # b,16, 168, 100\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 84, 50\n",
    "            nn.Conv2d(16, 8, 3, stride=3, padding=(0,2)),  # b, 8,28 , 18\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2)  # b, 8, 14, 9\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 29, 19\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 87, 57\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 3, 2, stride=2, padding=1),  # b, 3,172, 112\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(3, 1, 1, stride=3, padding=(7,17)),  # b, 1, 500, 300\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the custom dataloader\n",
    "def get_x(uid_list):\n",
    "    for i,uid in enumerate(uid_list):\n",
    "        x=dict_final_x[uid]\n",
    "        x=x.view(1,x.shape[0],x.shape[1],x.shape[2])\n",
    "        if(i==0):\n",
    "            out=x\n",
    "        else:\n",
    "            out = torch.cat((out, x), 0)\n",
    "    return out\n",
    "        \n",
    "def get_y(uid_list):\n",
    "    for i,uid in enumerate(uid_list):\n",
    "        y=dict_final_y[uid]\n",
    "        y=y.view(1,y.shape[0],y.shape[1],y.shape[2])\n",
    "        if(i==0):\n",
    "            out=y\n",
    "        else:\n",
    "            out = torch.cat((out, y), 0)\n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(list(dict_final_x.keys()), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss:5.7894\n",
      "epoch [2/200], loss:6.3604\n",
      "epoch [3/200], loss:4.9825\n",
      "epoch [4/200], loss:4.5573\n",
      "epoch [5/200], loss:6.6772\n",
      "epoch [6/200], loss:5.7825\n",
      "epoch [7/200], loss:2.8177\n",
      "epoch [8/200], loss:5.9521\n",
      "epoch [9/200], loss:2.9825\n",
      "epoch [10/200], loss:4.7508\n",
      "epoch [11/200], loss:6.5628\n",
      "epoch [12/200], loss:4.5567\n",
      "epoch [13/200], loss:3.3921\n",
      "epoch [14/200], loss:6.2799\n",
      "epoch [15/200], loss:3.2467\n",
      "epoch [16/200], loss:5.1613\n",
      "epoch [17/200], loss:2.8326\n",
      "epoch [18/200], loss:4.7941\n",
      "epoch [19/200], loss:2.6091\n",
      "epoch [20/200], loss:6.0078\n",
      "epoch [21/200], loss:6.1138\n",
      "epoch [22/200], loss:5.5218\n",
      "epoch [23/200], loss:4.5058\n",
      "epoch [24/200], loss:4.4397\n",
      "epoch [25/200], loss:6.9193\n",
      "epoch [26/200], loss:4.2754\n",
      "epoch [27/200], loss:3.9822\n",
      "epoch [28/200], loss:1.7212\n",
      "epoch [29/200], loss:4.9650\n",
      "epoch [30/200], loss:5.0659\n",
      "epoch [31/200], loss:2.5776\n",
      "epoch [32/200], loss:4.0145\n",
      "epoch [33/200], loss:4.0153\n",
      "epoch [34/200], loss:5.5040\n",
      "epoch [35/200], loss:5.2693\n",
      "epoch [36/200], loss:3.0655\n",
      "epoch [37/200], loss:5.1207\n",
      "epoch [38/200], loss:5.6470\n",
      "epoch [39/200], loss:5.5916\n",
      "epoch [40/200], loss:3.7479\n",
      "epoch [41/200], loss:3.8453\n",
      "epoch [42/200], loss:5.6619\n",
      "epoch [43/200], loss:5.0478\n",
      "epoch [44/200], loss:4.3441\n",
      "epoch [45/200], loss:4.8289\n",
      "epoch [46/200], loss:6.0675\n",
      "epoch [47/200], loss:1.9802\n",
      "epoch [48/200], loss:4.2663\n",
      "epoch [49/200], loss:3.9892\n",
      "epoch [50/200], loss:3.1338\n",
      "epoch [51/200], loss:5.5340\n",
      "epoch [52/200], loss:4.8801\n",
      "epoch [53/200], loss:6.8399\n",
      "epoch [54/200], loss:4.6444\n",
      "epoch [55/200], loss:6.2841\n",
      "epoch [56/200], loss:3.7435\n",
      "epoch [57/200], loss:2.9609\n",
      "epoch [58/200], loss:3.7215\n",
      "epoch [59/200], loss:5.3943\n",
      "epoch [60/200], loss:4.5741\n",
      "epoch [61/200], loss:5.9125\n",
      "epoch [62/200], loss:3.5535\n",
      "epoch [63/200], loss:5.4583\n",
      "epoch [64/200], loss:4.6880\n",
      "epoch [65/200], loss:5.4060\n",
      "epoch [66/200], loss:5.5257\n",
      "epoch [67/200], loss:3.7779\n",
      "epoch [68/200], loss:3.9330\n",
      "epoch [69/200], loss:3.8541\n",
      "epoch [70/200], loss:4.0279\n",
      "epoch [71/200], loss:3.7733\n",
      "epoch [72/200], loss:3.4376\n",
      "epoch [73/200], loss:4.4441\n",
      "epoch [74/200], loss:4.6849\n",
      "epoch [75/200], loss:3.6841\n",
      "epoch [76/200], loss:4.1224\n",
      "epoch [77/200], loss:2.8262\n",
      "epoch [78/200], loss:3.9885\n",
      "epoch [79/200], loss:4.4325\n",
      "epoch [80/200], loss:4.6997\n",
      "epoch [81/200], loss:3.3540\n",
      "epoch [82/200], loss:3.5771\n",
      "epoch [83/200], loss:3.9044\n",
      "epoch [84/200], loss:5.7790\n",
      "epoch [85/200], loss:4.1395\n",
      "epoch [86/200], loss:3.7606\n",
      "epoch [87/200], loss:4.4168\n",
      "epoch [88/200], loss:5.6874\n",
      "epoch [89/200], loss:2.6692\n",
      "epoch [90/200], loss:3.5077\n",
      "epoch [91/200], loss:4.2160\n",
      "epoch [92/200], loss:3.5685\n",
      "epoch [93/200], loss:3.9842\n",
      "epoch [94/200], loss:3.5640\n",
      "epoch [95/200], loss:4.9277\n",
      "epoch [96/200], loss:3.4760\n",
      "epoch [97/200], loss:4.4556\n",
      "epoch [98/200], loss:3.9284\n",
      "epoch [99/200], loss:5.2400\n",
      "epoch [100/200], loss:3.3112\n",
      "epoch [101/200], loss:4.7648\n",
      "epoch [102/200], loss:4.6582\n",
      "epoch [103/200], loss:4.5060\n",
      "epoch [104/200], loss:4.0238\n",
      "epoch [105/200], loss:5.1663\n",
      "epoch [106/200], loss:5.6007\n",
      "epoch [107/200], loss:4.1187\n",
      "epoch [108/200], loss:3.0974\n",
      "epoch [109/200], loss:2.6137\n",
      "epoch [110/200], loss:4.4016\n",
      "epoch [111/200], loss:3.7997\n",
      "epoch [112/200], loss:3.4086\n",
      "epoch [113/200], loss:6.1022\n",
      "epoch [114/200], loss:3.4934\n",
      "epoch [115/200], loss:4.8874\n",
      "epoch [116/200], loss:3.5192\n",
      "epoch [117/200], loss:3.1518\n",
      "epoch [118/200], loss:2.4785\n",
      "epoch [119/200], loss:4.5011\n",
      "epoch [120/200], loss:2.3497\n",
      "epoch [121/200], loss:3.6880\n",
      "epoch [122/200], loss:3.9683\n",
      "epoch [123/200], loss:5.4794\n",
      "epoch [124/200], loss:5.1173\n",
      "epoch [125/200], loss:4.5456\n",
      "epoch [126/200], loss:3.7229\n",
      "epoch [127/200], loss:4.3574\n",
      "epoch [128/200], loss:4.4795\n",
      "epoch [129/200], loss:6.6329\n",
      "epoch [130/200], loss:5.4526\n",
      "epoch [131/200], loss:4.9479\n",
      "epoch [132/200], loss:3.8203\n",
      "epoch [133/200], loss:6.3069\n",
      "epoch [134/200], loss:3.4458\n",
      "epoch [135/200], loss:4.5676\n",
      "epoch [136/200], loss:3.0058\n",
      "epoch [137/200], loss:5.0035\n",
      "epoch [138/200], loss:4.2917\n",
      "epoch [139/200], loss:3.4229\n",
      "epoch [140/200], loss:5.0081\n",
      "epoch [141/200], loss:4.2707\n",
      "epoch [142/200], loss:3.9517\n",
      "epoch [143/200], loss:2.3398\n",
      "epoch [144/200], loss:3.8419\n",
      "epoch [145/200], loss:5.2264\n",
      "epoch [146/200], loss:3.2804\n",
      "epoch [147/200], loss:3.8246\n",
      "epoch [148/200], loss:3.7278\n",
      "epoch [149/200], loss:5.6875\n",
      "epoch [150/200], loss:4.1580\n",
      "epoch [151/200], loss:3.7803\n",
      "epoch [152/200], loss:2.9993\n",
      "epoch [153/200], loss:4.3450\n",
      "epoch [154/200], loss:4.6301\n",
      "epoch [155/200], loss:3.3180\n",
      "epoch [156/200], loss:4.2767\n",
      "epoch [157/200], loss:6.2402\n",
      "epoch [158/200], loss:5.0963\n",
      "epoch [159/200], loss:5.0166\n",
      "epoch [160/200], loss:5.0937\n",
      "epoch [161/200], loss:6.0786\n",
      "epoch [162/200], loss:5.6340\n",
      "epoch [163/200], loss:4.2617\n",
      "epoch [164/200], loss:4.2745\n",
      "epoch [165/200], loss:6.1996\n",
      "epoch [166/200], loss:3.0321\n",
      "epoch [167/200], loss:5.4595\n",
      "epoch [168/200], loss:4.2774\n",
      "epoch [169/200], loss:4.6648\n",
      "epoch [170/200], loss:6.3930\n",
      "epoch [171/200], loss:3.9286\n",
      "epoch [172/200], loss:2.5036\n",
      "epoch [173/200], loss:3.3897\n",
      "epoch [174/200], loss:5.4945\n",
      "epoch [175/200], loss:5.2419\n",
      "epoch [176/200], loss:5.9767\n",
      "epoch [177/200], loss:4.5584\n",
      "epoch [178/200], loss:3.7266\n",
      "epoch [179/200], loss:4.8285\n",
      "epoch [180/200], loss:2.5701\n",
      "epoch [181/200], loss:4.4482\n",
      "epoch [182/200], loss:4.9652\n",
      "epoch [183/200], loss:2.7280\n",
      "epoch [184/200], loss:1.7065\n",
      "epoch [185/200], loss:4.5493\n",
      "epoch [186/200], loss:3.2612\n",
      "epoch [187/200], loss:3.1865\n",
      "epoch [188/200], loss:5.6961\n",
      "epoch [189/200], loss:5.2657\n",
      "epoch [190/200], loss:4.8355\n",
      "epoch [191/200], loss:5.6357\n",
      "epoch [192/200], loss:4.2372\n",
      "epoch [193/200], loss:5.1019\n",
      "epoch [194/200], loss:4.5358\n",
      "epoch [195/200], loss:3.9150\n",
      "epoch [196/200], loss:4.5726\n",
      "epoch [197/200], loss:4.2146\n",
      "epoch [198/200], loss:3.2669\n",
      "epoch [199/200], loss:2.1560\n",
      "epoch [200/200], loss:5.7413\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = get_x(data)\n",
    "        img_out=get_y(data)\n",
    "        img_out=img_out.cuda()\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img_out)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs+200):\n",
    "    for data in dataloader:\n",
    "        img = get_x(data)\n",
    "        img_out=get_y(data)\n",
    "        img_out=img_out.cuda()\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img_out)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainX_17000_1channel.pickle', 'wb') as handle:\n",
    "    pickle.dump(dict_final_x, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainX_17000_1channel.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_final_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
